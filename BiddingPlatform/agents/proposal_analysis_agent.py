# agents/proposal_analysis_agent.py
from typing import Dict, Any, List
import re
import json
import asyncio
from .base_agent import BaseAgent, AgentTask, AgentResult, AgentStatus
from langchain_google_genai import ChatGoogleGenerativeAI

class ProposalAnalysisAgent(BaseAgent):
    """Agent specialized in analyzing individual proposals against evaluation criteria"""
    
    def __init__(self, agent_id: str = None, config: Dict[str, Any] = None):
        super().__init__(agent_id, config)
        self.llm = config.get('llm') if config else None
        if not self.llm:
            raise ValueError("LLM instance required for ProposalAnalysisAgent")
        
        self.max_concurrent_analysis = config.get('max_concurrent_analysis', 2) if config else 2
    
    def get_capabilities(self) -> List[str]:
        return [
            "proposal_content_analysis",
            "criteria_matching",
            "strength_identification",
            "weakness_detection",
            "evidence_extraction"
        ]
    
    async def process_task(self, task: AgentTask) -> AgentResult:
        """Process proposal analysis tasks"""
        task_type = task.input_data.get('task_type')
        
        if task_type == 'analyze_single_proposal':
            return await self._analyze_single_proposal(task)
        elif task_type == 'analyze_batch_proposals':
            return await self._analyze_batch_proposals(task)
        elif task_type == 'extract_strengths':
            return await self._extract_proposal_strengths(task)
        else:
            raise ValueError(f"Unknown task type: {task_type}")
    
    async def _analyze_single_proposal(self, task: AgentTask) -> AgentResult:
        """Analyze a single proposal against criteria"""
        proposal = task.input_data.get('proposal')
        criteria = task.input_data.get('criteria', [])
        
        if not proposal or not criteria:
            raise ValueError("Proposal and criteria required for analysis")
        
        company_name = proposal.get('company_name')
        proposal_text = proposal.get('pdf_text', '')
        
        # Analyze each criterion
        criterion_analyses = []
        for criterion in criteria:
            analysis = await self._analyze_criterion_match(
                proposal_text, criterion, company_name
            )
            criterion_analyses.append(analysis)
        
        # Extract overall strengths and weaknesses
        overall_analysis = await self._extract_overall_analysis(
            proposal_text, criteria, company_name
        )
        
        return AgentResult(
            task_id=task.task_id,
            agent_id=self.agent_id,
            status=AgentStatus.COMPLETED,
            output_data={
                'company_name': company_name,
                'criterion_analyses': criterion_analyses,
                'overall_analysis': overall_analysis,
                'proposal_quality': self._assess_proposal_quality(criterion_analyses)
            }
        )
    
    async def _analyze_batch_proposals(self, task: AgentTask) -> AgentResult:
        """Analyze multiple proposals concurrently"""
        proposals = task.input_data.get('proposals', [])
        criteria = task.input_data.get('criteria', [])
        
        if not proposals or not criteria:
            raise ValueError("Proposals and criteria required for batch analysis")
        
        # Process proposals concurrently with semaphore
        semaphore = asyncio.Semaphore(self.max_concurrent_analysis)
        analysis_tasks = []
        
        for proposal in proposals:
            task_coro = self._analyze_single_proposal_with_semaphore(
                semaphore, proposal, criteria
            )
            analysis_tasks.append(task_coro)
        
        results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
        
        # Process results
        successful_analyses = []
        failed_analyses = []
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                failed_analyses.append({
                    'company_name': proposals[i].get('company_name', f'Company_{i}'),
                    'error': str(result)
                })
            else:
                successful_analyses.append(result)
        
        return AgentResult(
            task_id=task.task_id,
            agent_id=self.agent_id,
            status=AgentStatus.COMPLETED,
            output_data={
                'successful_analyses': successful_analyses,
                'failed_analyses': failed_analyses,
                'success_count': len(successful_analyses),
                'failure_count': len(failed_analyses)
            }
        )
    
    async def _analyze_single_proposal_with_semaphore(self, semaphore: asyncio.Semaphore, 
                                                     proposal: Dict, criteria: List[Dict]):
        """Analyze single proposal with concurrency control"""
        async with semaphore:
            return await self._analyze_single_proposal_internal(proposal, criteria)
    
    async def _analyze_single_proposal_internal(self, proposal: Dict, criteria: List[Dict]):
        """Internal method for analyzing a single proposal"""
        company_name = proposal.get('company_name')
        proposal_text = proposal.get('pdf_text', '')
        
        # Analyze each criterion
        criterion_analyses = []
        for criterion in criteria:
            analysis = await self._analyze_criterion_match(
                proposal_text, criterion, company_name
            )
            criterion_analyses.append(analysis)
        
        # Extract overall analysis
        overall_analysis = await self._extract_overall_analysis(
            proposal_text, criteria, company_name
        )
        
        return {
            'company_name': company_name,
            'criterion_analyses': criterion_analyses,
            'overall_analysis': overall_analysis,
            'proposal_quality': self._assess_proposal_quality(criterion_analyses)
        }
    
# ------------------------------------------------------------------ #
#  â¬‡ï¸ Ø§Ø³ØªØ¨Ø¯Ù„ Ø§Ù„Ø¯Ø§Ù„Ø© _analyze_criterion_match ÙƒØ§Ù…Ù„Ø© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¥ØµØ¯Ø§Ø±
# ------------------------------------------------------------------ #
    async def _analyze_criterion_match(self, proposal_text: str, criterion: Dict,
                                       company_name: str) -> Dict[str, Any]:
        """Analyze how well a proposal matches a specific criterion via LLM (with fallback)."""
        criterion_name = criterion.get('name', '')
        criterion_desc = criterion.get('description', '')

        # Limit text length for LLM processing
        text_sample = proposal_text[:4000]  # Ø³Ù…Ø­Ù†Ø§ Ø¨Ù…Ù‚ØªØ·Ù Ø£ÙƒØ¨Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹

        prompt = f"""
Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯ÙˆØ±: Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªÙ‚ÙŠÙŠÙ… Ø¹Ø±ÙˆØ¶ (Technical & Financial Proposal Evaluator) Ù„Ø¯Ù‰ Ø¬Ù‡Ø© Ø­ÙƒÙˆÙ…ÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ©.

ğŸ§® **Ø§Ù„Ù‡Ø¯Ù**: Ù‚ÙŠØ§Ø³ Ù…Ø¯Ù‰ Ø§Ø³ØªÙŠÙØ§Ø¡ Ø¹Ø±Ø¶ Ø´Ø±ÙƒØ© Â«{company_name}Â» Ù„Ù…Ø¹ÙŠØ§Ø± Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ÙˆØ¶Ù‘ÙØ­ Ø£Ø¯Ù†Ø§Ù‡ØŒ Ù…Ø¹ ØªØ¨Ø±ÙŠØ± Ø§Ù„Ø¯Ø±Ø¬Ø© Ø¨Ø§Ù„Ø£Ø¯Ù„Ø©.

ğŸ“‹ **Ø§Ù„Ù…Ø¹ÙŠØ§Ø± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù**
â€¢ Ø§Ù„Ø§Ø³Ù…   : {criterion_name}
â€¢ Ø§Ù„ÙˆØµÙ   : {criterion_desc}

ğŸ“‘ **Ù…Ù‚ØªØ·Ù Ù…Ù† Ø§Ù„Ø¹Ø±Ø¶** (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ù‚ØªØ·Ø¹Ø§Ù‹):
\"\"\" 
{text_sample}
\"\"\" 

ğŸ› ï¸ **Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ â€“ Ø£Ø¹Ø¯Ù‡ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø· ÙˆØ¯ÙˆÙ† Ø£ÙŠ ØªØ¹Ù„ÙŠÙ‚ Ø¢Ø®Ø±**:
{{
  "score": <Ø¹Ø¯Ø¯ ØµØ­ÙŠØ­ 0-100Ø› 90+ = Ù…Ù…ØªØ§Ø²ØŒ 75-89 = Ø¬ÙŠØ¯ØŒ 60-74 = Ù…ØªÙˆØ³Ø·ØŒ Ø£Ù‚Ù„ Ù…Ù† 60 = Ø¶Ø¹ÙŠÙ>,
  "strengths": ["..."],
  "weaknesses": ["..."],
  "evidence": ["Ø§Ù‚ØªØ¨Ø§Ø³ Ù‚ØµÙŠØ± â‰¤ 200 Ø­Ø±Ù ÙŠØ¯Ø¹Ù… Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"],
  "justification": "Ø¬Ù…Ù„Ø© Ù…Ø®ØªØµØ±Ø© ØªÙ„Ø®Ù‘Øµ Ø³Ø¨Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø©"
}}

âš ï¸ **ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¥Ù„Ø²Ø§Ù…ÙŠØ©**
â€¢ Ø§Ù„ØªØ²Ù… ØªÙ…Ø§Ù…Ø§Ù‹ Ø¨Ø§Ù„Ø¨Ù†Ø§Ø¡ JSON Ø£Ø¹Ù„Ø§Ù‡Ø› Ù„Ø§ ØªØ¶Ù Ø£Ùˆ ØªØ­Ø°Ù Ø­Ù‚ÙˆÙ„Ø§Ù‹.  
â€¢ Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø£ÙŠ Ø°ÙƒØ± ÙˆØ§Ø¶Ø­ Ù„Ù„Ù…Ø·Ù„ÙˆØ¨ØŒ Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¯Ø±Ø¬Ø© 0 ÙˆØ³Ø¬Ù‘Ù„ Ø¶Ø¹ÙØ§Ù‹ Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹.  
â€¢ Ø§Ù„Ø£Ø¯Ù„Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù‚ØªØ¨Ø§Ø³Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ (ÙŠÙ…ÙƒÙ† ØªÙ‚ØµÙŠØ±Ù‡Ø§ Ø¨Ø¹Ù„Ø§Ù…Ø© â€œâ€¦â€) ÙˆÙ„Ø§ ØªØªØ¬Ø§ÙˆØ² 200 Ø­Ø±Ù.
"""

        try:
            response = self.llm.invoke(prompt)
            result_text = response.content if hasattr(response, "content") else str(response)

            # Extract JSON from response
            json_match = re.search(r"\{[\s\S]*\}", result_text)
            if json_match:
                analysis = json.loads(json_match.group(0))

                # Sanity-check score
                score_val = analysis.get("score", 0)
                if not isinstance(score_val, (int, float)) or not (0 <= score_val <= 100):
                    score_val = 50

                return {
                    "criterion_name": criterion_name,
                    "score": score_val,
                    "strengths": analysis.get("strengths", []),
                    "weaknesses": analysis.get("weaknesses", []),
                    "evidence": analysis.get("evidence", []),
                    "justification": analysis.get("justification", ""),
                }

        except Exception as e:
            self.logger.warning(f"LLM analysis failed for criterion {criterion_name}: {e}")

        # --- Fallback: keyword-based quick estimate ---
        return self._fallback_criterion_analysis(proposal_text, criterion)
    
    def _fallback_criterion_analysis(self, proposal_text: str, criterion: Dict) -> Dict[str, Any]:
        """Fallback analysis when LLM fails"""
        criterion_name = criterion.get('name', '')
        
        # Simple keyword-based scoring
        keywords = self._get_criterion_keywords(criterion_name)
        score = self._calculate_keyword_score(proposal_text, keywords)
        
        return {
            'criterion_name': criterion_name,
            'score': score,
            'strengths': ["ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ù…ØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ù…Ø¹ÙŠØ§Ø±"],
            'weaknesses': ["ÙŠØ­ØªØ§Ø¬ ØªØ­Ù„ÙŠÙ„ Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹"],
            'evidence': [],
            'justification': f"ØªÙ‚ÙŠÙŠÙ… Ø£ÙˆÙ„ÙŠ Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© - {score}/100"
        }
    
# ------------------------------------------------------------------ #
#  â¬‡ï¸ Ø§Ø³ØªØ¨Ø¯Ù„ Ø§Ù„Ø¯Ø§Ù„Ø© _get_criterion_keywords ÙƒØ§Ù…Ù„Ø© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¥ØµØ¯Ø§Ø±
# ------------------------------------------------------------------ #
    def _get_criterion_keywords(self, criterion_name: str) -> List[str]:
        """Return a richer Arabic/English keyword list relevant to the criterion name."""
        keyword_map = {
            # Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„ÙÙ†ÙŠØ© / Technical Competence
            "Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„ÙÙ†ÙŠØ©": [
                "ØªÙ‚Ù†ÙŠ", "ØªÙƒÙ†ÙˆÙ„ÙˆØ¬", "Ø®Ø¨Ø±Ø©", "Ù…Ù‡Ø§Ø±Ø©", "Ø§Ø¨ØªÙƒØ§Ø±", "Ù…Ø¹Ù…Ø§Ø±ÙŠØ©", "ØªÙƒØ§Ù…Ù„",
                "ØµÙŠØ§Ù†Ø©", "Ø¯Ø¹Ù…", "SLA", "Ø£Ù…Ù†", "Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠØ©", "Ø¬ÙˆØ¯Ø©", "Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ©",
                "performance", "security", "integration", "maintenance"
            ],
            # Ø§Ù„Ø®Ø¨Ø±Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© / Past Experience
            "Ø§Ù„Ø®Ø¨Ø±Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©": [
                "Ø®Ø¨Ø±Ø©", "Ù…Ø´Ø±ÙˆØ¹", "ØªÙ†ÙÙŠØ°", "Ø¥Ù†Ø¬Ø§Ø²", "Ù…Ø±Ø¬Ø¹", "Ø¹Ù…ÙŠÙ„", "Ù†Ø¬Ø§Ø­",
                "Ø­Ø§Ù„Ø©", "case study", "Ø´Ù‡Ø§Ø¯Ø©", "reference", "tor", "ØªØ­Ø§Ù„Ù", "ØªÙˆØ±ÙŠØ¯"
            ],
            # Ø®Ø·Ø© Ø§Ù„ØªÙ†ÙÙŠØ° ÙˆØ§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ / Implementation Plan
            "Ø®Ø·Ø© Ø§Ù„ØªÙ†ÙÙŠØ°": [
                "Ø®Ø·Ø©", "Ø¬Ø¯ÙˆÙ„", "Ø²Ù…Ù†ÙŠ", "Ù…Ø±Ø­Ù„Ø©", "Ù…Ø³Ø§Ø±", "Ù†Ø´Ø§Ø·", "Ù…ÙˆØ¹Ø¯", "ØªÙˆØ±ÙŠØ¯",
                "Ù…ÙˆØ§Ø±Ø¯", "Ù…Ø®Ø§Ø·Ø±", "ØªØ­ÙƒÙ…", "Ù…Ù†Ù‡Ø¬ÙŠØ©", "agile", "waterfall", "sprint",
                "Gantt", "timeline"
            ],
            # ÙØ±ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ / Project Team
            "ÙØ±ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„": [
                "ÙØ±ÙŠÙ‚", "Ù‡ÙŠÙƒÙ„", "Ø³ÙŠØ±Ø©", "CV", "Ù…Ù‡Ù†Ø¯Ø³", "Ù…Ø­Ù„Ù„", "Ù…Ø¯ÙŠØ± Ù…Ø´Ø±ÙˆØ¹",
                "Ù…ØªØ®ØµØµ", "Ø®Ø¨ÙŠØ±", "Ø´Ù‡Ø§Ø¯Ø©", "PMP", "Ø®Ø¨Ø±Ø§Øª", "Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©",
                "team structure", "staff", "consultant"
            ],
            # Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ© / Financial Offer
            "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©": [
                "Ø³Ø¹Ø±", "ØªÙƒÙ„ÙØ©", "Ø¹Ø±Ø¶ Ù…Ø§Ù„ÙŠ", "Ù…Ø§Ù„ÙŠ", "Ù…ÙŠØ²Ø§Ù†ÙŠØ©", "Ø¯ÙØ¹", "Ø®ØµÙ…",
                "Ù‚ÙŠÙ…Ø©", "ÙˆÙØ±", "ÙØ¹Ø§Ù„ÙŠØ©", "ROI", "Ø¬Ø¯ÙˆÙ‰", "cost", "price", "economy"
            ],
            # Ù…Ø¯Ù‰ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ù…ÙˆØ§ØµÙØ§Øª / Compliance
            "Ù…Ø¯Ù‰ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©": [
                "Ù…Ø·Ø§Ø¨Ù‚Ø©", "Ù…ÙˆØ§ØµÙØ©", "Ù…ØªØ·Ù„Ø¨Ø§Øª", "ØªÙˆØ§ÙÙ‚", "compliance", "iso",
                "Ø³ÙŠØ§Ø³Ø©", "Ù…Ø¹ÙŠØ§Ø±", "Ù„Ø§Ø¦Ø­Ø©", "Ø¶Ù…Ø§Ù†", "Ù…Ø¹ØªÙ…Ø¯", "Ù…ØªÙˆØ§ÙÙ‚"
            ],
            # Ø®Ø·Ø© Ø§Ù„ØªØ³Ù„ÙŠÙ… / Delivery
            "Ø§Ù„ØªØ³Ù„ÙŠÙ…": [
                "ØªØ³Ù„ÙŠÙ…", "Ù…Ø¯Ø©", "Ù…Ù‡Ù„Ø©", "Ø¬Ø¯ÙˆÙ„", "Ø®Ø¯Ù…Ø©", "ØªØ´ØºÙŠÙ„", "commissioning",
                "handover", "CPM", "milestone", "Ù…ÙˆØ¹Ø¯ Ù†Ù‡Ø§Ø¦ÙŠ", "deadline"
            ],
            # Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚ / Past Performance
            "Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚": [
                "Ø£Ø¯Ø§Ø¡", "Ù…Ø¤Ø´Ø±", "kpi", "kpi", "Ø±Ø¶Ø§", "satisfaction", "ØªÙ‚ÙŠÙŠÙ…",
                "Ù…Ø±Ø¬Ø¹ÙŠØ©", "Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©", "reliability", "uptime", "SLR", "slo"
            ],
        }

        # Pick the first key whose words appear in the criterion_name
        for key, words in keyword_map.items():
            if any(part in criterion_name for part in key.split()):
                return words

        # Generic fallback keywords
        return ["Ø¬ÙˆØ¯Ø©", "ØªÙ…ÙŠØ²", "ÙƒÙØ§Ø¡Ø©", "Ø§Ø­ØªØ±Ø§Ù", "value", "best practice"]
    
    def _calculate_keyword_score(self, text: str, keywords: List[str]) -> int:
        """Calculate a simple score based on keyword presence"""
        text_lower = text.lower()
        found_keywords = sum(1 for keyword in keywords if keyword in text_lower)
        
        # Base score of 40, plus 10 points per found keyword (max 100)
        score = min(40 + (found_keywords * 10), 100)
        return score
    
    async def _extract_overall_analysis(self, proposal_text: str, criteria: List[Dict], 
                                      company_name: str) -> Dict[str, Any]:
        """Extract overall strengths and weaknesses of the proposal"""
        # Limit text for processing
        text_sample = proposal_text[:1500] if len(proposal_text) > 1500 else proposal_text
        criteria_names = [c.get('name', '') for c in criteria]
        
        prompt = f"""
        Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ø·Ø§Ø¡Ø§Øª. ÙŠØ±Ø¬Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ù†ÙŠ Ø¨Ø´ÙƒÙ„ Ø´Ø§Ù…Ù„.
        
        Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {', '.join(criteria_names)}
        
        Ù†Øµ Ø§Ù„Ø¹Ø±Ø¶:
        {text_sample}
        
        Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
        1. Ø­Ø¯Ø¯ Ø£Ø¨Ø±Ø² 3 Ù†Ù‚Ø§Ø· Ù‚ÙˆØ© ÙÙŠ Ø§Ù„Ø¹Ø±Ø¶
        2. Ø­Ø¯Ø¯ Ø£Ø¨Ø±Ø² 3 Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø£Ùˆ Ù…Ø¬Ø§Ù„Ø§Øª ØªØ­Ø³ÙŠÙ†
        3. Ù‚ÙŠÙ‘Ù… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¹Ø±Ø¶ Ø¹Ù…ÙˆÙ…Ø§Ù‹ (Ù…Ù…ØªØ§Ø²/Ø¬ÙŠØ¯/Ù…ØªÙˆØ³Ø·/Ø¶Ø¹ÙŠÙ)
        
        Ø£Ø±Ø¬Ø¹ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ JSON:
        {{
            "overall_strengths": ["Ù†Ù‚Ø·Ø© Ù‚ÙˆØ© 1", "Ù†Ù‚Ø·Ø© Ù‚ÙˆØ© 2", "Ù†Ù‚Ø·Ø© Ù‚ÙˆØ© 3"],
            "overall_weaknesses": ["Ù†Ù‚Ø·Ø© Ø¶Ø¹Ù 1", "Ù†Ù‚Ø·Ø© Ø¶Ø¹Ù 2"],
            "overall_quality": "Ø¬ÙŠØ¯",
            "summary": "Ù…Ù„Ø®Øµ Ù‚ØµÙŠØ± Ø¹Ù† Ø§Ù„Ø¹Ø±Ø¶"
        }}
        """
        
        try:
            response = self.llm.invoke(prompt)
            result_text = response.content if hasattr(response, 'content') else str(response)
            
            json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
            if json_match:
                json_text = json_match.group(0)
                return json.loads(json_text)
            
        except Exception as e:
            self.logger.warning(f"Overall analysis failed: {e}")
        
        # Fallback
        return {
            'overall_strengths': ["Ø¹Ø±Ø¶ ÙÙ†ÙŠ Ù…ØªÙƒØ§Ù…Ù„"],
            'overall_weaknesses': ["ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© ØªÙØµÙŠÙ„ÙŠØ©"],
            'overall_quality': "Ù…ØªÙˆØ³Ø·",
            'summary': f"Ø¹Ø±Ø¶ ØªÙ‚Ù†ÙŠ Ù…Ù† {company_name}"
        }
    
    def _assess_proposal_quality(self, criterion_analyses: List[Dict]) -> Dict[str, Any]:
        """Assess overall proposal quality based on criterion analyses"""
        if not criterion_analyses:
            return {'quality_score': 0, 'quality_level': 'Ø¶Ø¹ÙŠÙ'}
        
        # Calculate average score
        scores = [analysis.get('score', 0) for analysis in criterion_analyses]
        avg_score = sum(scores) / len(scores)
        
        # Determine quality level
        if avg_score >= 85:
            quality_level = 'Ù…Ù…ØªØ§Ø²'
        elif avg_score >= 70:
            quality_level = 'Ø¬ÙŠØ¯'
        elif avg_score >= 50:
            quality_level = 'Ù…ØªÙˆØ³Ø·'
        else:
            quality_level = 'Ø¶Ø¹ÙŠÙ'
        
        return {
            'quality_score': round(avg_score, 1),
            'quality_level': quality_level,
            'score_distribution': scores,
            'min_score': min(scores),
            'max_score': max(scores)
        }
    
    async def _extract_proposal_strengths(self, task: AgentTask) -> AgentResult:
        """Extract key strengths from a proposal for justification"""
        proposal = task.input_data.get('proposal')
        criteria = task.input_data.get('criteria', [])
        
        if not proposal:
            raise ValueError("Proposal required for strength extraction")
        
        analysis = await self._analyze_single_proposal_internal(proposal, criteria)
        
        # Compile top strengths with evidence
        strengths_with_evidence = []
        for criterion_analysis in analysis['criterion_analyses']:
            if criterion_analysis.get('score', 0) >= 70:  # Good scores
                for strength in criterion_analysis.get('strengths', []):
                    strengths_with_evidence.append({
                        'strength': strength,
                        'criterion': criterion_analysis['criterion_name'],
                        'score': criterion_analysis['score'],
                        'evidence': criterion_analysis.get('evidence', [])
                    })
        
        return AgentResult(
            task_id=task.task_id,
            agent_id=self.agent_id,
            status=AgentStatus.COMPLETED,
            output_data={
                'company_name': proposal.get('company_name'),
                'strengths_with_evidence': strengths_with_evidence,
                'overall_analysis': analysis.get('overall_analysis', {}),
                'top_criteria_scores': sorted(
                    [(ca['criterion_name'], ca['score']) for ca in analysis['criterion_analyses']],
                    key=lambda x: x[1], reverse=True
                )[:3]
            }
        )
